# Sp2
# project name: student performance errors analysis
# student names: khalifa saeed, mayed mohammed, mohammed yaqoob
# student skills: khalifa saeed: coding, mayed mohammed: programming and design, mohammed yaqoob: logistics and debugging

# The Student Exam Score Prediction project focuses on building a machine learning model to estimate students' exam scores based on a variety of features reflecting their academic habits, personal lifestyle, and socio-economic background. The dataset used includes attributes such as hours studied, attendance rates, average sleep hours, previous academic performance, family income level, access to the internet, involvement in extracurricular activities, and individual motivation levels. These features aim to provide a holistic view of the factors influencing student performance. The core machine learning model implemented is Linear Regression, a straightforward yet powerful technique for predicting continuous outcomes. Before training, the data undergoes preprocessing steps including encoding categorical variables and normalizing numerical values to ensure the model treats all inputs appropriately. The model was trained using Python with key data science libraries such as Pandas for data manipulation, NumPy for numerical operations, and Scikit-learn for building and evaluating the model. Optional visualizations may be generated using Matplotlib or Seaborn for better insight into the data and results. The model's effectiveness is evaluated using common regression metrics: Mean Absolute Error (MAE): 0.45, Mean Squared Error (MSE): 3.25, RÂ² Score: 0.77. These results suggest the model is fairly accurate, explaining around 77% of the variance in student scores. The project structure includes a Jupyter Notebook (student-exam-score-prediction-model.ipynb) containing all data preprocessing, modeling, and evaluation steps, and a README.md file that outlines the purpose and setup of the project. Planned future improvements involve experimenting with more advanced algorithms like RandomForest and XGBoost, conducting feature importance analysis to understand which variables most affect performance, and applying hyperparameter tuning to further optimize model accuracy.
